/**
 * ===========================
 * GEMmaker Configuration File
 * ===========================
 *
 * This file provides the configuration settings for the GEMmaker workflow.
 */
manifest {
  mainScript = "main.nf"
  defaultBranch = "master"
  nextflowVersion = ">=0.32.0"
}



params {
  input {
    remote_list_path = "${PWD}/examples/RemoteRunExample/SRA_IDs.txt"
    local_samples_path = "${PWD}/examples/LocalRunExample/Sample*/*_{1,2}.fastq"
    reference_path = "${PWD}/examples/reference/"
    reference_prefix = "CORG"
  }

  output {
    dir = "${PWD}/output"
    sample_dir = { "${params.output.dir}/${sample_id}" }
    publish_mode = "link"
    publish_trimmed_fastq = true
    publish_bam = true
  }

  execution {
    queue_size = 100
    threads = 1
    max_retries = 2
    error_strategy = "ignore"
  }

  software {
    trimmomatic {
      clip_path = "${PWD}/files/fasta_adapter.txt"
      MINLEN = "0.7"
      quality = ""
      SLIDINGWINDOW = "4:15"
      LEADING = "3"
      TRAILING = "6"
    }

    /**
     * Alignment
     *
     * User chooses between hisat2, Kallisto or Salmon. If hisat2 is chosen,
     * processes "samtools_sort", "samtools_index" and "stringtie" will also be
     * done. All processes will end with a gene abundance file.
     * Aligns reads to the reference genome.
     */
    alignment {
      //
      // hisat2 = 0
      // Kallisto = 1
      // Salmon = 2
      //
      which_alignment = 0
    }

    fpkm_or_tpm {
      fpkm = true
      tpm = true
    }
  }
}



report {
  file = "${params.output.dir}/report.html"
}



timeline {
  file = "${params.output.dir}/timeline.html"
}



trace {
  fields = "task_id,hash,native_id,process,tag,name,status,exit,module,container,cpus,time,disk,memory,attempt,submit,start,complete,duration,realtime,queue,%cpu,%mem,rss,vmem,peak_rss,peak_vmem,rchar,wchar,syscr,syscw,read_bytes,write_bytes"
  file = "${params.output.dir}/trace.txt"
  raw = true
}



docker {
  fixOwnership = true
  runOptions = "--init"
  sudo = true
}



singularity {
  runOptions = ""
}



process {
  container = "systemsgenetics/gemmaker"

  withLabel:rate_limit {
    maxForks = 1
  }
  withLabel:retry {
    errorStrategy = { "${task.attempt}" == "${params.execution.max_retries}" ? "retry" : "${params.execution.error_strategy}" }
  }

  withLabel:fastqc {
    container = "systemsgenetics/fastqc:0.11.7"
    time = "24h"
  }
  withLabel:hisat2 {
    container = "systemsgenetics/hisat2:2.1.0"
    time = "48h"
  }
  withLabel:kallisto {
    container = "systemsgenetics/kallisto:0.45.0"
    time = "24h"
  }
  withLabel:python3 {
    container = "systemsgenetics/python3:1.0.0"
    time = "1h"
  }
  withLabel:salmon {
    container = "systemsgenetics/salmon:0.12.0"
    time = "24h"
  }
  withLabel:samtools {
    container = "systemsgenetics/samtools:1.9"
    time = "48h"
  }
  withLabel:sratoolkit {
    container = "systemsgenetics/sratoolkit:2.9.2"
    time = "48h"
  }
  withLabel:stringtie {
    container = "systemsgenetics/stringtie:1.3.4d"
    time = "48h"
  }
  withLabel:trimmomatic {
    container = "systemsgenetics/trimmomatic:0.38"
    time = "72h"
  }
}



profiles {
  standard {
    process.executor = "local"
  }

  testing {
    process.errorStrategy = "terminate"
  }

  //
  // Clemson's Palmetto cluster uses the PBS scheduler. Here we provide
  // an example for execution of this workflow on Palmetto with some
  // defaults for all steps of the workflow.
  //
  // Since the PBS resource list does not support disk or local scratch,
  // we must use a custom resource list in order to guarantee a certain
  // amount of local scratch space. In this case, we select nodes from phases
  // on Palmetto which have plenty of local scratch and tend to be highly
  // available. Additionally, nextflow does not properly support the "ncpus"
  // and "mem" options in PBS Professional, so we must specify these resources
  // using "clusterOptions" instead of the "cpus" and "mem" directives.
  //

  pbs {
    process {
      executor = "pbs"
      time = "8h"
      scratch = true
      stageInMode = "copy"

      withLabel: "multithreaded" {
        clusterOptions = "-l select=1:phase=4:mem=8gb:ncpus=${params.execution.threads}"
      }
      withLabel: "!multithreaded" {
        clusterOptions = "-l select=1:phase=4:mem=2gb:ncpus=2"
      }

      withLabel:fastqc {
        module "fastQC"
      }
      withLabel:hisat2 {
        module "hisat2"
      }
      withLabel:python3 {
        module "anaconda3"
      }
      withLabel:samtools {
        module "samtools"
      }
      withLabel:sratoolkit {
        module "sratoolkit"
      }
      withLabel:stringtie {
        module "stringtie"
      }
      withLabel:trimmomatic {
        module "trimmomatic"
      }
    }
    executor {
      queueSize = "${params.execution.queue_size}"
    }
  }

  //
  // WSU's Kamiak cluster uses the SLURM scheduler. Here we provide
  // an example for execution of this workflow on Kamiak with some
  // defaults for all steps of the workflow.
  //
  slurm {
    process {
      executor = "slurm"
      queue = "ficklin"
      time = "4h"

      withLabel: "multithreaded" {
        cpus = "${params.execution.threads}"
      }
      withLabel: "!multithreaded" {
        cpus = 1
      }

      withLabel:fastqc {
        module "fastQC"
      }
      withLabel:hisat2 {
        module "hisat2"
      }
      withLabel:python3 {
        module "python3"
      }
      withLabel:samtools {
        module "samtools"
      }
      withLabel:sratoolkit {
        module "sratoolkit"
      }
      withLabel:stringtie {
        module "stringtie"
      }
      withLabel:trimmomatic {
        module "trimmomatic"
      }
    }
    executor {
      queueSize = "${params.execution.queue_size}"
    }
  }
}
